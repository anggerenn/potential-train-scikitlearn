{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "## To be consistent with sentiment use Enums\n",
    "class Sentiment:\n",
    "    bad = \"MAD BAD\"\n",
    "    neutral = \"MEH\"\n",
    "    good = \"RAD CHAD\"\n",
    "\n",
    "## Make it neat by using class\n",
    "class Review:\n",
    "    def __init__(self, text, star):\n",
    "        self.text = text #reviews['reviewText'][0]\n",
    "        self.star = star #reviews['overall'][1]\n",
    "        self.sentiment = self.get_sentiment() # create new object to for star\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.star < 3:\n",
    "            return Sentiment.bad\n",
    "        elif self.star == 3:\n",
    "            return Sentiment.neutral\n",
    "        else:\n",
    "            return Sentiment.good\n",
    "    \n",
    "        \n",
    "### Improve model result\n",
    "### Evenly distribute positive and negative         \n",
    "class ReviewContainer:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "    \n",
    "    ### Make it neat to get text and sentiment\n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "    \n",
    "    def evenly_distribute(self):\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.good, self.reviews))\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.bad, self.reviews))\n",
    "        positive_shrunk = positive[:len(negative)]\n",
    "        self.reviews = negative + positive_shrunk\n",
    "        random.shuffle(self.reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "The whole series was great!  Melody is a fantastic writer and keeps you intrigues the for the entire book love it!\n",
      "5.0\n",
      "RAD CHAD\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# file_name = './data/books_small.json'\n",
    "\n",
    "### Improve model result\n",
    "### Load larger dataset\n",
    "file_name = './data/Books_small_10000.json'\n",
    "\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'], review['overall']))\n",
    "\n",
    "## Alternative 1\n",
    "#       reviews.append(review['reviewText'], review['overall'])             \n",
    "# \n",
    "# Use index to get specific review or rating\n",
    "# reviews[-5][1] # Return 5.0\n",
    "#\n",
    "# Rather than append to tuple we can append to class object (Review) instead\n",
    "\n",
    "\n",
    "    \n",
    "print(len(reviews))\n",
    "print(reviews[-5].text)\n",
    "print(reviews[-5].star)\n",
    "print(reviews[-5].sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, test = train_test_split(reviews, test_size=0.33, random_state=42)\n",
    "\n",
    "# print(len(test))\n",
    "\n",
    "### Make it neat using class\n",
    "train_cont = ReviewContainer(training)\n",
    "test_cont = ReviewContainer(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RAD CHAD', 'RAD CHAD', 'MAD BAD']\n",
      "['MAD BAD', 'MAD BAD', 'RAD CHAD']\n",
      "436\n",
      "436\n",
      "208\n",
      "208\n"
     ]
    }
   ],
   "source": [
    "# Get text and sentiment from training data\n",
    "### Make it neat using class\n",
    "train_cont.evenly_distribute() ### Evenly distribute positive and negative train data\n",
    "train_x = train_cont.get_text()\n",
    "train_y = train_cont.get_sentiment()\n",
    "\n",
    "print(train_y[12:15])\n",
    "\n",
    "# Get text and sentiment from test data\n",
    "test_cont.evenly_distribute() #### do the same with test data\n",
    "test_x = test_cont.get_text()\n",
    "test_y = test_cont.get_sentiment()\n",
    "\n",
    "print(test_y[12:15])\n",
    "print(train_y.count(Sentiment.good))\n",
    "print(train_y.count(Sentiment.bad))\n",
    "print(test_y.count(Sentiment.good))\n",
    "print(test_y.count(Sentiment.bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(872, 8906)\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "(416, 8906)\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing text\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # CountVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_x) # this is a test data no need to fit data only transform\n",
    "\n",
    "print(train_x_vectors.shape)\n",
    "print(train_x_vectors[0].toarray())\n",
    "print(test_x_vectors.shape)\n",
    "\n",
    "## We can also break it down in two steps\n",
    "# vectorizer.fit(train_y)\n",
    "# train_y_vectors = vectorizer.transform(train_y)\n",
    "\n",
    "# print(train_y_vectors.shape) # Return (670, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is something about the quiet old guy in the novels that draws me to a book, this book was a very good read\n",
      "['RAD CHAD']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n",
    "print(test_x[0])\n",
    "# test_x_vectors[0]\n",
    "\n",
    "print(clf_svm.predict(test_x_vectors[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is something about the quiet old guy in the novels that draws me to a book, this book was a very good read\n",
      "['RAD CHAD']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "\n",
    "print(test_x[0])\n",
    "# test_x_vectors[0]\n",
    "\n",
    "print(clf_dec.predict(test_x_vectors[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RAD CHAD']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "\n",
    "clf_gnb.fit(train_x_vectors.toarray(), train_y)\n",
    "\n",
    "# print(test_x[0])\n",
    "print(clf_gnb.predict(test_x_vectors[0].toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is something about the quiet old guy in the novels that draws me to a book, this book was a very good read\n",
      "['RAD CHAD']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "\n",
    "clf_log.fit(train_x_vectors, train_y)\n",
    "\n",
    "print(test_x[0])\n",
    "print(clf_log.predict(test_x_vectors[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "How to determine if a model is good or not? we can use Mean Accuracy and F1 to measure its performance. \n",
    "\n",
    "Between those two which one is more important? It depend of what we're looking for, Accuracy is used when the True Positives and True negatives are more important while F1-score is used when the False Negatives and False Positives are crucial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      " 0.8076923076923077\n",
      "DEC:\n",
      " 0.6370192307692307\n",
      "GNB:\n",
      " 0.6610576923076923\n",
      "LOG:\n",
      " 0.8052884615384616\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM:\\n\", clf_svm.score(test_x_vectors, test_y))\n",
    "print(\"DEC:\\n\", clf_dec.score(test_x_vectors, test_y))\n",
    "print(\"GNB:\\n\", clf_gnb.score(test_x_vectors.toarray(), test_y))\n",
    "print(\"LOG:\\n\", clf_log.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows better results for SVM mean accuracy.\n",
    "\n",
    "Before using TfidfVectorizer:\n",
    "- SVM:\n",
    " 0.7980769230769231\n",
    "- DEC:\n",
    " 0.6298076923076923\n",
    "- GNB:\n",
    " 0.6346153846153846\n",
    "- LOG:\n",
    " 0.8149038461538461\n",
    "\n",
    "It gets better than just evenly distributing (+) and (-) on training data, but using smaller dataset and not random distribute stil gives best result\n",
    "\n",
    "Before evenly distribute (+) and (-) test data:\n",
    "- SVM:\n",
    " 0.7124242424242424\n",
    "- DEC:\n",
    " 0.6209090909090909\n",
    "- GNB:\n",
    " 0.44575757575757574\n",
    "- LOG:\n",
    " 0.7448484848484849\n",
    "\n",
    "It gets worse.\n",
    "\n",
    "Before load larger dataset and evenly distribute (+) and (-):\n",
    "- SVM:\n",
    " 0.8242424242424242\n",
    "- DEC:\n",
    " 0.7575757575757576\n",
    "- GNB:\n",
    " 0.8121212121212121\n",
    "- LOG:\n",
    " 0.8303030303030303\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      " [0.80582524 0.80952381]\n",
      "DEC:\n",
      " [0.63260341 0.64133017]\n",
      "GNB:\n",
      " [0.65693431 0.66508314]\n",
      "LOG:\n",
      " [0.80291971 0.80760095]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "### Leave out Sentiment.neutral because we don't need it\n",
    "print(\"SVM:\\n\", f1_score(test_y, clf_svm.predict(test_x_vectors), average=None, labels=[Sentiment.good, Sentiment.bad]))#, Sentiment.neutral)\n",
    "print(\"DEC:\\n\", f1_score(test_y, clf_dec.predict(test_x_vectors), average=None, labels=[Sentiment.good, Sentiment.bad]))#, Sentiment.bad]))\n",
    "print(\"GNB:\\n\", f1_score(test_y, clf_gnb.predict(test_x_vectors.toarray()), average=None, labels=[Sentiment.good, Sentiment.bad]))#, Sentiment.bad]))\n",
    "print(\"LOG:\\n\", f1_score(test_y, clf_log.predict(test_x_vectors), average=None, labels=[Sentiment.good, Sentiment.bad]))#, Sentiment.bad]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using TfidfVectorizer, LOG F1 score has insignificant increase while the rest has lower performance.\n",
    "\n",
    "- SVM:\n",
    " [0.8028169  0.79310345]\n",
    "- DEC:\n",
    " [0.63849765 0.62068966]\n",
    "- GNB:\n",
    " [0.59574468 0.66666667]\n",
    "- LOG:\n",
    " [0.82051282 0.808933  ]\n",
    "\n",
    "\n",
    "After evenly distribute test data like training data, the F1 results shows passable result.\n",
    "\n",
    "Before:\n",
    "- SVM:\n",
    " [0.85363477 0.28146853]\n",
    "- DEC:\n",
    " [0.76241722 0.18433818]\n",
    "- GNB:\n",
    " [0.6199765  0.15049505]\n",
    "- LOG:\n",
    " [0.8783008  0.31077216]\n",
    "\n",
    "While the Mean Accuracy decreased, The F1 Score shows insignificant increase after after load larger dataset and evenly distribute (+) and (-) training data.\n",
    "\n",
    "Before:\n",
    "- SVM:\n",
    " [0.91319444 0.21052632 0.22222222]\n",
    "- DEC:\n",
    " [0.86428571 0.15151515 0.11764706]\n",
    "- GNB:\n",
    " [0.89678511 0.08510638 0.09090909]\n",
    "- LOG:\n",
    " [0.91370558 0.12244898 0.1       ]\n",
    " \n",
    " This is the results without changing anything.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "436"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_y.count(Sentiment.good))\n",
    "train_y.count(Sentiment.bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model gives us good number of Mean Accuracy with F1 Score skewed toward good sentiment because the data heavily bias on it.\n",
    "\n",
    "What we can try to improve the model result:\n",
    "- get larger dataset and evenly distribute positive and negative train data\n",
    "\n",
    "it get worse on Mean Accuracy and insignificant increase on F1 bad sentiment score\n",
    "\n",
    "- evenly distribute the same thing of test data and only use LOG model as it gives the best result\n",
    "\n",
    "Based on F1 Score we can see better result on good and bad sentiment\n",
    "\n",
    "- use TfidfVectorizer\n",
    "\n",
    "It gives better result for SMV Mean Accuracy and LOG F1 Score\n",
    "\n",
    "- Tune the model using Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuned with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1320: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': [1, 4, 8, 16, 32], 'kernel': ('linear', 'rbf')})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# We will use LOG as it shows better result for F1 Score\n",
    "parameters_log = {'penalty':('l1', 'l2', 'elasticnet', 'none'), 'C':[1,4,8,16,32]}\n",
    "parameters_svm = {'kernel':('linear', 'rbf'), 'C':[1,4,8,16,32]}\n",
    "\n",
    "clf_log_grid = GridSearchCV(clf_log, parameters_log, cv=5)\n",
    "clf_log_grid.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_svm_grid = GridSearchCV(clf_svm, parameters_svm, cv=5)\n",
    "clf_svm_grid.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After GridSearch\n",
      "SVM Accuracy:\n",
      " 0.8052884615384616\n",
      "SVM F1 Score:\n",
      " [0.8057554  0.80481928]\n",
      "LOG Accuracy:\n",
      " 0.8149038461538461\n",
      "LOG F1 Score:\n",
      " [0.81967213 0.80987654]\n"
     ]
    }
   ],
   "source": [
    "print(\"After GridSearch\")\n",
    "\n",
    "print(\"SVM Accuracy:\\n\", clf_svm_grid.score(test_x_vectors, test_y))\n",
    "print(\"SVM F1 Score:\\n\", f1_score(test_y, clf_svm_grid.predict(test_x_vectors), average=None, labels=[Sentiment.good, Sentiment.bad]))#, Sentiment.bad]))\n",
    "\n",
    "print(\"LOG Accuracy:\\n\", clf_log_grid.score(test_x_vectors, test_y))\n",
    "print(\"LOG F1 Score:\\n\", f1_score(test_y, clf_log_grid.predict(test_x_vectors), average=None, labels=[Sentiment.good, Sentiment.bad]))#, Sentiment.bad]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gives worse results for SVM but better results for LOG. (Even though it returns error and I don't know how to fix it, but I feel content with these now)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save/Load Model using Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./model/sentiment_svm_clf.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_svm_grid, f)\n",
    "    \n",
    "with open('./model/sentiment_log_clf.pkl', 'wb') as f:\n",
    "    pickle.dump(clf_log_grid, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./model/sentiment_svm_clf.pkl', 'rb') as f:\n",
    "#     loaded_svm_clf = pickle.load(f)\n",
    "    \n",
    "with open('./model/sentiment_log_clf.pkl', 'rb') as f:\n",
    "    loaded_log_clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved this book and the previous books in this series. It brings out every emotion you can think of. I look forward to reading more books by this author.\n",
      "['RAD CHAD']\n"
     ]
    }
   ],
   "source": [
    "print(test_x[9])\n",
    "# print(loaded_svm_clf.predict(test_x_vectors[9]))\n",
    "\n",
    "print(loaded_log_clf.predict(test_x_vectors[9]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
